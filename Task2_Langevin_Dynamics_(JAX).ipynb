{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_D4pQGBFlmi"
      },
      "source": [
        "# Лабораторная работа по методам Монте-Карло\n",
        "\n",
        "В рамках данной работы предлагается:\n",
        "- Реализовать динамику Ланжевена для сэмплирования из апостериорного распределения\n",
        "- Реализовать стохастическую динамику Ланжевена для сэмплирования из апостериорного распределения\n",
        "- Применить оба метода на модельной задаче оценки параметров смеси нормальных распределений\n",
        "- *(бонусная часть)* Применить динамику Ланжевена для генерации изображений\n",
        "\n",
        "Оценка ставится на основе дополненного кода в ячейках (вычисление градиентов в модельной задаче, динамика Ланжевена и стохастическая динамика Ланжевена), а также ответов на вопросы по экспериментам. В бонусной части задания в качестве ненормированной плотности используется выход сверточной нейронной сети, поэтому для её выполнения вам может потребоваться GPU, облачный сервер или немного терпения.\n",
        "\n",
        "Полезные источники:\n",
        "\n",
        "- Welling M., Teh Y. W. Bayesian learning via stochastic gradient Langevin dynamics // Proceedings of the 28th International Conference on Machine Learning (ICML-11). – 2011. – С. 681-688.\n",
        "- Neal R. M. et al. MCMC using Hamiltonian dynamics // Handbook of Markov Chain Monte Carlo. – 2011. – Т. 2. – №. 11\n",
        "- Grathwohl W. et al. Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One // ICLR 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee5dL4y7Flmm"
      },
      "source": [
        "Критерии оценки:\n",
        "1. Функции для вычисления плотностей в модельной задаче - 2 балла\n",
        "2. Стохастическая динамика Ланжевена - 2 балла\n",
        "3. Динамика Ланжевена - 2 балла\n",
        "4. Комментарии к экспериментам 1 - 1.5 балл\n",
        "5. Комментарии к экспериментам 2 - 1.5 балл\n",
        "6. Комментарии к экспериментам 3 - 1 балл\n",
        "7. Бонусная часть - 2 балла максимум"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckmxru0WFlmn"
      },
      "outputs": [],
      "source": [
        "# Библиотеки, использованные при разработке задания:\n",
        "# numpy==1.19.2\n",
        "# jax==0.2.3\n",
        "# matplotlib==3.3.2\n",
        "# tqdm==4.50.2\n",
        "# torch==1.6.0\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as onp\n",
        "import jax.numpy as np\n",
        "import jax\n",
        "\n",
        "import copy\n",
        "import gzip\n",
        "import os\n",
        "\n",
        "from jax.scipy.stats import norm\n",
        "from tqdm import tqdm\n",
        "\n",
        "# убираем warning если у вас нет gpu или tpu\n",
        "jax.config.update('jax_platform_name', 'cpu')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqPs_dyvFlmo"
      },
      "source": [
        "### Пара слов о библиотеках для лабораторной работы\n",
        "\n",
        "Поскольку для динамики Ланжевена нужны градиенты плотности, в этой работе мы воспользуемся библиотекой JAX для их подсчета. JAX переобределяет большую часть библиотеки numpy в модуле jax.numpy и добавляет возможности для\n",
        "- Автоматическго построения градиентов функций;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zpxu3P3Flmp"
      },
      "outputs": [],
      "source": [
        "def foo(x):\n",
        "    return np.sin(x)\n",
        "\n",
        "grad_foo = jax.grad(foo)\n",
        "x = 0.\n",
        "print(\"f(0) = {}, f'(0) = {}\".format(foo(x), grad_foo(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE9DMtjDFlmp"
      },
      "source": [
        "- Векторизации функций;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7XRPx5fFlmp"
      },
      "outputs": [],
      "source": [
        "# np.cos и так векторизован, но jax.vmap добавлять векторную размерность и для более сложных питоновских функций\n",
        "vector_grad_foo = jax.vmap(grad_foo)\n",
        "# vector_grad_foo(0.) теперь не заработает\n",
        "vector_grad_foo(0.5 * np.pi * np.arange(8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YBFyO7hFlmq"
      },
      "source": [
        "- Выполнения вычислений на ускорителях и компиляции функций \"just-in-time\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hzEFKcEFlmq"
      },
      "outputs": [],
      "source": [
        "x = 0.5 * np.pi * np.arange(100)\n",
        "\n",
        "%timeit vector_grad_foo(x)\n",
        "vector_grad_foo = jax.jit(vector_grad_foo) # компилируем функцию\n",
        "%timeit vector_grad_foo(x)\n",
        "%timeit np.cos(x) # так работает библиотечная функция"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZo2IDxuFlmq"
      },
      "source": [
        "Модуль jax.numpy можно использовать аналогично библиотеке numpy. Главным исключением является генерация случайных чисел: для этого в jax есть модуль jax.random, о котором можно прочитать [тут](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#%F0%9F%94%AA-Random-Numbers). **Tl;dr: для генерации каждый раз нужно передавать уникальный ключ.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i66HX2NYFlmr"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(seed=42)\n",
        "rng, key = jax.random.split(rng)\n",
        "n = jax.random.normal(key, (3,))\n",
        "print('Random sample:\\n{}'.format(n))\n",
        "n = jax.random.normal(key, (3,))\n",
        "print('Same key, same sample:\\n{}'.format(n))\n",
        "rng, key = jax.random.split(rng)\n",
        "n = jax.random.normal(key, (3, ))\n",
        "print('New key, new sample:\\n{}'.format(n))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELnpLyeHFlmr"
      },
      "source": [
        "Рекомендуем использовать jax.random при сэмплировании в динамике Ланжевена: он быстрее и \"случайней\". Тем не менее, для простоты мы будем инициализировать веса с помощью *numpy.random*.\n",
        "\n",
        "# Задача оценки параметров смеси распределений\n",
        "\n",
        "> Рассмотрим вероятностную модель, в которой данные приходят из смеси нормальных распределений:\n",
        "\n",
        ">\\begin{align}\n",
        "& \\theta_1 \\sim N(0,\\sigma_1^2); \\quad \\theta_2 \\sim N(0, \\sigma_2^2) \\\\\n",
        "& \\\\\n",
        "& x_i \\overset{i.i.d.}{\\sim} \\frac{1}{2} N(\\theta_1, \\sigma_x^2) + \\frac{1}{2} N(\\theta_1 + \\theta_2, \\sigma_x^2) \\quad i=1,\\dots,N \\\\\n",
        "\\end{align}\n",
        "\n",
        ">На $\\theta_1$ и $\\theta_2$ введены априорные нормальные распределения, а все остальные параметры полагаются равными\n",
        "\\begin{align}\n",
        "& \\sigma_x^2 = 2 \\\\\n",
        "& \\sigma_1^2 = 10 \\\\\n",
        "& \\sigma_2^2 = 1 \\\\\n",
        "\\end{align}\n",
        "\n",
        ">Требуется по сгеренированной с параметрами $\\theta_1 = 0$, $\\theta_2 = 1$ выборке $X$ из $N=100$ элементов построить сэмплы из апостериорного распределения $p({\\bar \\theta} | X, \\sigma_x, \\sigma_1, \\sigma_2)$.\n",
        "\n",
        "Построим выборку из данного распределения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG6nRTx-Flmr"
      },
      "outputs": [],
      "source": [
        "def generate_mixture_data(N, theta_1=None, theta_2=None, seed=6):\n",
        "    \"\"\"\n",
        "    Функция геренирует выобрку данного размера из описанной выше вероятностной модели.\n",
        "    В случае, когда для theta_1 или theta_2 передано скалярное значение, вместо случайного\n",
        "    значения параметра из априорного распределения используется переданное значение.\n",
        "    \"\"\"\n",
        "    onp.random.seed(seed)\n",
        "    sigma_x = np.sqrt(2.)\n",
        "    if theta_1 is None:\n",
        "        sigma_1 = np.sqrt(10.)\n",
        "        theta_1 = sigma_1 * onp.random.randn()\n",
        "    if theta_2 is None:\n",
        "        sigma_2 = 1.\n",
        "        theta_2 = sigma_2 * onp.random.randn()\n",
        "    mixture_component = onp.random.randint(0, 2, N).astype(onp.bool)\n",
        "    first_component = theta_1 + sigma_x * onp.random.randn(N)\n",
        "    second_component = (theta_1 + theta_2) + sigma_x * onp.random.randn(N)\n",
        "    samples = np.where(mixture_component,\n",
        "                       first_component,\n",
        "                       second_component)\n",
        "    return samples\n",
        "\n",
        "# Пример выборки из описанной выше модели\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "ax.hist(generate_mixture_data(2048), bins=50, density=True)\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Empirical probability');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaguFof6Flmr"
      },
      "source": [
        "Наша главная цель - по полученной при фиксированных значениях $\\theta_1$ и $\\theta_2$ выборке построить апостериорное распределение на их значения.\n",
        "\n",
        "\\begin{equation}\n",
        "p({\\bar \\theta} | X, \\sigma_x, \\sigma_1, \\sigma_2) \\propto \\left[ \\prod_{i=1}^{N} p(X| {\\bar \\theta}, \\sigma_x) \\right] p(\\theta | \\sigma_1, \\sigma_2)\n",
        "\\end{equation}\n",
        "\n",
        "Хотя задача и допускает аналитический подсчет апостериорного распределения, после раскрытия скобок оно будет представлять из себя смесь $2^N$ нормальных распределений. Поэтому даже для такой простой задачи аналитический вывод может оказаться неэффективным на практике.\n",
        "\n",
        "Методы Монте-Карло позволяют получить сэмплы из апостериорного распределения.\n",
        "\n",
        "> Для наших целей нам понядобятся функции для подсчета плотности априорного распределения и логарифма правдоподобия. Реализуйте их:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1R3uwdEFlmr"
      },
      "outputs": [],
      "source": [
        "def log_p_prior(weights):\n",
        "    \"\"\"\n",
        "    Логарифм плотности априорного распределения.\n",
        "    Вход:\n",
        "        weights - вектор из двух вещественных чисел \\theta_1, \\theta_2\n",
        "    Выход: число\n",
        "    \"\"\"\n",
        "    ###################\n",
        "    # Допишите функцию #\n",
        "    ###################\n",
        "    pass\n",
        "\n",
        "def log_p_likelihood(weights, x):\n",
        "    \"\"\"\n",
        "    Возвращает логарифм правдоподобия данных x относительно параметров weights\n",
        "    Вход:\n",
        "        weights - вектор из двух вещественных чисел \\theta_1, \\theta_2,\n",
        "        x - данные, представленные вектором фиксированной длины\n",
        "    Выход: число\n",
        "    \"\"\"\n",
        "    ###################\n",
        "    # Допишите функцию #\n",
        "    ###################\n",
        "    pass\n",
        "\n",
        "def log_p_joint(weights, x):\n",
        "    return log_p_likelihood(weights, x) + log_p_prior(weights)\n",
        "\n",
        "# Определим функцию для градиента и векторизуем обе функции для подсчета по батчу параметров:\n",
        "grad_log_p_joint = jax.grad(log_p_joint)\n",
        "# векторизуем только по первому аргументу\n",
        "log_p_joint = jax.vmap(log_p_joint, (0, None))\n",
        "grad_log_p_joint = jax.vmap(grad_log_p_joint, (0, None))\n",
        "# компиляция для ускорения, можете попробовать опустить этот шаг\n",
        "log_p_joint = jax.jit(log_p_joint)\n",
        "grad_log_p_joint = jax.jit(grad_log_p_joint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7t3QkmCFlms"
      },
      "source": [
        "Согласно задаче, к нам поступает полученная со значениями $\\theta_1=0$ и $\\theta_2=1$ выборка из ста наблюдений $x_i$.\n",
        "\n",
        "Изобразим приближенно плотность аспостериорного распределения в зависимости от числа поступивших наблюдений:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moZovunBFlms"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(seed=42)\n",
        "rng, key = jax.random.split(rng)\n",
        "data = generate_mixture_data(N=100, theta_1=0, theta_2=1)\n",
        "\n",
        "def plot_posterior(axes, data, resolution=100):\n",
        "    theta_1 = np.linspace(-1., 2., resolution)\n",
        "    theta_2 = np.linspace(-2., 2., resolution)\n",
        "    X, Y = np.meshgrid(theta_1, theta_2)\n",
        "    weights = np.stack((X.reshape(-1), Y.reshape(-1)), 1)\n",
        "    log_probs = log_p_joint(weights, data)\n",
        "    log_probs = log_probs - log_probs.max()\n",
        "    Z = np.exp(log_probs - log_probs.max())\n",
        "    norm_const = np.sum(Z) * 3 * 4 / resolution ** 2\n",
        "    Z /= norm_const\n",
        "    Z = Z.reshape((resolution, resolution))\n",
        "\n",
        "    CS = axes.contour(X, Y, Z)\n",
        "    axes.set_xlabel(r'$\\theta_1$')\n",
        "    axes.set_ylabel(r'$\\theta_2$')\n",
        "\n",
        "Ns = (10, 20, 50, 100,)\n",
        "fig, axes = plt.subplots(ncols=len(Ns), figsize=(15, 3))\n",
        "for n, ax in zip(Ns, axes):\n",
        "    plot_posterior(ax, data[:n])\n",
        "    ax.set_title('N = %d' % n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwtJ9aLuFlms"
      },
      "source": [
        "> У апостериорного распределения на последнем графике должны быть две ярко выраженные моды. Чем это можно объяснить?"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "4RSjE09-Flms"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_xWVyveFlms"
      },
      "source": [
        "> Ниже необходимо реализовать функции для построения сэмплов из апостериорного распределения:\n",
        "\n",
        "> 1. Стохастическая динамика Ланжевена. Для реализации достаточно слегка модифицировать предложенную реализацию градиентного подъема\n",
        "> 2. Динамика Ланжевена с приятием точек по схеме Метрополиса-Гастингса\n",
        "    - Вычисление новых весов\n",
        "    - Подсчет вероятности их принятия\n",
        "    - Случайное принятие части весов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj8DSk3VFlms"
      },
      "outputs": [],
      "source": [
        "def gradient_ascent_update(epsilon, gradient, weights, rng):\n",
        "    return weights + 0.5 * epsilon * gradient\n",
        "\n",
        "def stochastic_langevin_update(epsilon, gradient, weights, rng):\n",
        "    \"\"\"\n",
        "    Стохастическая динамика Ланжевена\n",
        "    Вход:\n",
        "        epsilon - размер шага градиента\n",
        "        gradient - вещественная матрица с градиентами для пар $\\theta$\n",
        "        weights -  вещественная матрица с параметрами $\\theta$\n",
        "        rng - сид для генерации случайных чисел\n",
        "    Выход:\n",
        "        вещественная матрица, соответствующая обновленным параметрам $\\theta$\n",
        "    \"\"\"\n",
        "    ###################\n",
        "    # Допишите функцию #\n",
        "    ###################\n",
        "    pass\n",
        "\n",
        "def mh_acceptance_ratio(epsilon, weights, new_weights):\n",
        "    \"\"\"\n",
        "    Динамика Ланжевена\n",
        "    Вход:\n",
        "        epsilon - размер шага градиента\n",
        "        weights -  вещественная матрица с параметрами $\\theta$\n",
        "        new_weigts - параметры, полученные после шага схемы Ланжевена\n",
        "    Выход:\n",
        "        вещественный вектор, задающий логарифм вероятности принятия каждой пары из батча\n",
        "    \"\"\"\n",
        "\n",
        "    ###################\n",
        "    # Допишите функцию #\n",
        "    ###################\n",
        "    pass\n",
        "\n",
        "def langevin_update(epsilon, gradient, weights, rng):\n",
        "    \"\"\"\n",
        "    Динамика Ланжевена\n",
        "    Вход:\n",
        "        epsilon - размер шага градиента\n",
        "        gradient - вещественная матрица с градиентами для пар $\\theta$\n",
        "        weights -  вещественная матрица с параметрами $\\theta$\n",
        "        rng - сид для генерации случайных чисел\n",
        "    Выход:\n",
        "        вещественная матрица, соответствующая обновленным параметрам $\\theta$\n",
        "        вещественное число, доля принятых точек из батча\n",
        "    \"\"\"\n",
        "    ###################\n",
        "    # Допишите функцию #\n",
        "    ###################\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO5JUowLFlms"
      },
      "source": [
        "## Динамика Ланжевена на модельной задаче\n",
        "\n",
        "Для проведения эксперимента определим несколько вспомогательных функций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlNwSJcdFlms"
      },
      "outputs": [],
      "source": [
        "def append_ema(array, value, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Добавление элементов в массив с экспоненциальным сглаживанием\n",
        "    \"\"\"\n",
        "    if not array:\n",
        "        array.append(value)\n",
        "    else:\n",
        "        array.append((1 - alpha) * array[-1] + alpha * value)\n",
        "    return array\n",
        "\n",
        "def train_mixture(data, weights, epsilon, n_epochs=2000, n_trajectories=5):\n",
        "    \"\"\"\n",
        "    Построение точек из апостериорного распределения с помощью динамики Ланжевена\n",
        "    Параллельно с построением точек сохраняются траектории n_trajectories точек и динамика\n",
        "    acceptance_rate\n",
        "    \"\"\"\n",
        "    rng = jax.random.PRNGKey(27)\n",
        "    acceptance_rate = []\n",
        "    theta_dynamics = []\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        theta_dynamics.append(copy.copy(weights[:n_trajectories]))\n",
        "        gradient = grad_log_p_joint(weights, data)\n",
        "        rng, key = jax.random.split(rng)\n",
        "        weights, accepted = langevin_update(epsilon, gradient, weights, key)\n",
        "        append_ema(acceptance_rate, accepted)\n",
        "    theta_dynamics = np.asarray(theta_dynamics)\n",
        "    return weights, acceptance_rate, theta_dynamics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbVWw8rEFlmt"
      },
      "source": [
        "Запустим M схем Ланжевена с шагом $\\varepsilon = 10^{-3}$ и с шагом $\\varepsilon = 10^{-4}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqyH8PFPFlmt"
      },
      "outputs": [],
      "source": [
        "M = 128\n",
        "\n",
        "weights_a = onp.random.randn(M, 2)\n",
        "weights_b = onp.random.randn(M, 2)\n",
        "\n",
        "weights_a, acceptance_rates_a, theta_dynamics_a = train_mixture(data, weights_a, 1e-3)\n",
        "weights_b, acceptance_rates_b, theta_dynamics_b = train_mixture(data, weights_b, 1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXpC-249Flmt"
      },
      "source": [
        "В следующей ячейке строится четыре графика:\n",
        "1. Два множества M точек из параллельно запущенных динамик Ланжевена после 2000 итераций\n",
        "2. Динамика пяти точек из схемы с шагом $\\varepsilon=10^{-3}$\n",
        "3. Динамика пяти точек из схемы с шагом $\\varepsilon=10^{-4}$\n",
        "4. Доля принятых точек (из M параллельных динамик) после каждой итерации для разных шагов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrI9sqRKFlmt"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 14))\n",
        "\n",
        "plot_posterior(axes[0][0], data)\n",
        "axes[0][0].scatter(weights_a[..., 0],\n",
        "                   weights_a[..., 1],\n",
        "                   marker='o',\n",
        "                   c='goldenrod',\n",
        "                   label=r'$\\varepsilon=10^{-2}$')\n",
        "axes[0][0].scatter(weights_b[..., 0],\n",
        "                   weights_b[..., 1],\n",
        "                   marker='v',\n",
        "                   c='deepskyblue',\n",
        "                   label=r'$\\varepsilon=10^{-4}$')\n",
        "axes[0][0].set_title('GLD samples after 2000 steps')\n",
        "axes[0][0].legend(loc='upper right')\n",
        "\n",
        "plot_posterior(axes[0][1], data)\n",
        "plot_posterior(axes[1][0], data)\n",
        "axes[0][1].set_title(r'GLD point dynamics, $\\varepsilon=10^{-3}$')\n",
        "axes[1][0].set_title(r'GLD point dynamics, $\\varepsilon=10^{-4}$')\n",
        "\n",
        "for i in range(5):\n",
        "    axes[0][1].plot(theta_dynamics_a[:, i, 0], theta_dynamics_a[:, i, 1])\n",
        "    axes[1][0].plot(theta_dynamics_b[:, i, 0], theta_dynamics_b[:, i, 1])\n",
        "\n",
        "axes[1][1].plot(acceptance_rates_a, label=r'$\\varepsilon=10^{-3}$', ls=':', c='goldenrod')\n",
        "axes[1][1].plot(acceptance_rates_b, label=r'$\\varepsilon=10^{-4}$', ls='-', c='deepskyblue')\n",
        "axes[1][1].set_title('Metropolis-Hastings acceptance rate')\n",
        "axes[1][1].set_xlabel('Epoch')\n",
        "axes[1][1].set_ylabel(r'EMA of acceptance rate, $\\alpha = 0.05$')\n",
        "axes[1][1].legend(loc='lower right');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB4Swe1MFlmt"
      },
      "source": [
        "> На основе этих графиков ответьте на следующие вопросы:\n",
        "- Хорошо ли точки покрывают апостериорное распределение?\n",
        "- Удается ли точкам \"перепрыгнуть\" с одной моды на другую?\n",
        "- Как меняется доля принятых точек в зависимости от величины шага?\n",
        "- Исходя из каких соображений стоит выбирать длину шага в динамике Ланжевена?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZTbMz6OFlmt"
      },
      "source": [
        "## Стохастическая динамика Ланжевена на модельной задаче\n",
        "\n",
        "Для проведения следующего эксперимента определим еще несколько вспомогательных функций"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Knxbkjr4Flmt"
      },
      "outputs": [],
      "source": [
        "# стохастическая оценка совместного правдоподобия\n",
        "def log_p_joint_estimate(weights, x, N_over_n):\n",
        "    return N_over_n * log_p_likelihood(weights, x) + log_p_prior(weights)\n",
        "# стохастический градиент\n",
        "grad_log_p_joint_estimate = jax.grad(log_p_joint_estimate)\n",
        "\n",
        "log_p_joint_estimate = jax.jit(jax.vmap(log_p_joint_estimate, (0, None, None)))\n",
        "grad_log_p_joint_estimate = jax.jit(jax.vmap(grad_log_p_joint_estimate, (0, None, None)))\n",
        "\n",
        "# определим вектор градиентов $\\nablda log p(x_i), i=1, \\dots, N$ для подсчета дисперсии относительно выбора данных\n",
        "batch_gradients = jax.vmap(jax.grad(log_p_likelihood), (None, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFP6KDXJFlmt"
      },
      "outputs": [],
      "source": [
        "def iterate_data(rng, length, batchsize=100, shuffle=True):\n",
        "    \"\"\"\n",
        "    Функция для прохода по выборке\n",
        "    \"\"\"\n",
        "    indices = onp.arange(length)\n",
        "    if shuffle:\n",
        "        onp.random.shuffle(indices)\n",
        "    for start_idx in range(0, length - batchsize + 1, batchsize):\n",
        "        yield indices[start_idx:start_idx + batchsize]\n",
        "\n",
        "def stochastic_train_mixture(rng, data, weights, method, n_epochs=2000, n=10, n_trajectories=5):\n",
        "    \"\"\"\n",
        "    Построение точек из апостериорного распределения с помощью стохастической динамики Ланжевена\n",
        "    Параллельно с построением точек сохраняются траектории n_trajectories точек после каждой эпохи,\n",
        "    оценки дисперий стохастического градиента и дисперсия добавочного шума динамики Ланжевена\n",
        "    \"\"\"\n",
        "    noise_vars = []\n",
        "    theta_vars = []\n",
        "    theta_dynamics = []\n",
        "    N_over_n = len(data) / n\n",
        "    steps_counter = 0\n",
        "    for epochs in tqdm(range(n_epochs)):\n",
        "        epsilon = 1e-1 * (steps_counter + 1e1) ** (-0.55)\n",
        "        rng, key = jax.random.split(rng)\n",
        "        for indices in iterate_data(key, len(data), n):\n",
        "            rng, key = jax.random.split(rng)\n",
        "            gradient = grad_log_p_joint_estimate(weights, data[indices], N_over_n)\n",
        "            weights = method(epsilon, gradient, weights, key)\n",
        "            steps_counter += 1\n",
        "\n",
        "        theta_dynamics.append(copy.copy(weights[:n_trajectories, :]))\n",
        "        # также как и в статье, оцениваем дисперсии по подвыборке\n",
        "        rng, key = jax.random.split(rng)\n",
        "        theta_grad = batch_gradients(weights, data)\n",
        "        theta_vars.append(theta_grad.var(0).max(0) * (0.5 * epsilon * N_over_n) ** 2 * n)\n",
        "        noise_vars.append(epsilon)\n",
        "\n",
        "    theta_dynamics = np.asarray(theta_dynamics)\n",
        "    theta_vars = np.asarray(theta_vars)\n",
        "    noise_vars = np.asarray(noise_vars)\n",
        "\n",
        "    return weights, noise_vars, theta_vars, theta_dynamics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdDAzzwIFlmt"
      },
      "source": [
        "Запустим стохастическую динамику Ланжевена и стохастический градиентный подъем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTJctBl4Flmt"
      },
      "outputs": [],
      "source": [
        "M = 128\n",
        "n = 10\n",
        "n_trajectories = 5\n",
        "\n",
        "weights_a = onp.random.randn(M, 2)\n",
        "weights_b = onp.random.randn(M, 2)\n",
        "\n",
        "weights_a, noise_vars_a, theta_vars_a, theta_dynamics_a = stochastic_train_mixture(\n",
        "    rng, data, weights_a, stochastic_langevin_update, n_epochs=200\n",
        ")\n",
        "\n",
        "weights_b, _, theta_vars_b, theta_dynamics_b = stochastic_train_mixture(\n",
        "    rng, data, weights_b, gradient_ascent_update, n_epochs=200\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbjlkPW1Flmt"
      },
      "source": [
        "В следующей ячейке строятся четыре графика:\n",
        "\n",
        "1. M точек из параллельно запущенных динамик Ланжевена после 2000 эпох и M точек из параллельно замущенных стохастических градиентных спусков после 2000 эпох\n",
        "2. Траектории пяти точек при движении согласно стохастической динамике Ланжевена\n",
        "3. Траектории пять точек при движении в направлении стохастического градиента\n",
        "4. Дисперсии стохастических градиентов и добавочного шума стохастической динамики Ланжевена в зависимости от эпохи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXPOXRLdFlmt"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 14))\n",
        "\n",
        "plot_posterior(axes[0][0], data, 200)\n",
        "axes[0][0].scatter(weights_a[:, 0],\n",
        "                   weights_a[:, 1],\n",
        "                   c='goldenrod',\n",
        "                   label='Stochastic Gradient Langevin Dynamics')\n",
        "axes[0][0].scatter(weights_b[:, 0],\n",
        "                   weights_b[:, 1],\n",
        "                   marker='v',\n",
        "                   c='deepskyblue',\n",
        "                   label='Stochastic Gradient Descent')\n",
        "axes[0][0].set_title('SGD vs. SGLD')\n",
        "axes[0][0].legend(loc='upper right')\n",
        "\n",
        "plot_posterior(axes[0][1], data)\n",
        "plot_posterior(axes[1][0], data)\n",
        "axes[0][1].set_title(r'SGLD point dynamics')\n",
        "axes[1][0].set_title(r'SGD point dynamics')\n",
        "\n",
        "for i in range(5):\n",
        "    axes[0][1].plot(theta_dynamics_a[:, i, 0], theta_dynamics_a[:, i, 1])\n",
        "    axes[1][0].plot(theta_dynamics_b[:, i, 0], theta_dynamics_b[:, i, 1])\n",
        "\n",
        "axes[1][1].set_title('Stochstic gradient variance')\n",
        "axes[1][1].set_yscale(\"log\", nonpositive='clip')\n",
        "axes[1][1].set_xscale(\"log\", nonpositive='clip')\n",
        "axes[1][1].plot(theta_vars_a[:, 0], label=r'SGLD $\\nabla \\theta_1$', c='goldenrod', ls=':')\n",
        "axes[1][1].plot(theta_vars_a[:, 1], label=r'SGLD $\\nabla \\theta_2$', c='deepskyblue', ls=':')\n",
        "axes[1][1].plot(theta_vars_b[:, 0], label=r'SGD $\\nabla \\theta_1$', c='goldenrod', ls='-')\n",
        "axes[1][1].plot(theta_vars_b[:, 1], label=r'SGD $\\nabla \\theta_2$', c='deepskyblue', ls='-')\n",
        "axes[1][1].plot(noise_vars_a, label=r'$\\varepsilon$', c='black')\n",
        "axes[1][1].set_xlabel('Epoch')\n",
        "axes[1][1].set_ylabel('log variance')\n",
        "axes[1][1].legend(loc='lower left');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "452YoMcXFlmu"
      },
      "source": [
        "> На основе графиков ответьте на следующие вопросы:\n",
        "1. Хорошо ли представленные точки покрывают апостериорное распределение? Где собираются точки после градиентного подъема?\n",
        "3. Удается ли стохастической динамике Ланжевена \"перепрыгнуть\" с одной моды на другую?\n",
        "4. Как соотносятся дисперсии стохастических градиентов с дисперсией добавленного шума динамики Ланжевена?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tvo4srr4Flmu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DndzjR_Flmu"
      },
      "source": [
        "# Бонусная часть\n",
        "\n",
        "В работе \"Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One\" авторы предлагают приближать ненормированную плотность $\\hat{p}(x, y)$ данных CIFAR-10 с помощью нейронной сети, разработанной для дискриминативной классификации. Обученная ими модель оказывается одновременно применима и для классификации, и для генерации данных. Для последнего как раз нужна схема Ланжевена.\n",
        "\n",
        "В этой части задания мы предлагаем реализовать схему для сэмплирования из предобученной модели, выложенной [в репозитории авторов](https://github.com/wgrathwohl/JEM/). Там также можно найти приближенную схему сэмплирования: без поправки Метрополиса-Гастингса и с несогласованными множителями перед градиентом и добавочным шумом.\n",
        "\n",
        "Попробуйте реализовать максимально обоснованную схему сэмплирования и получить сэмплы из CIFAR-10. Подумайте как выбор начальных точек влияет на скорость сэмплирования? Насколько хорошо определена плотность для аргумнетов, не похожих на изображения из CIFAR-10? Как реализовать условную и безусловную генерацию?\n",
        "\n",
        "Для удобства к заданию мы прикладываем скрипт, позволяющий загрузить предобученную модель, вычислить значение логарифма ненормированной плотности и градиентов плотности по входному изображению. Пример их использования дан ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxGHqNIFFlmu"
      },
      "outputs": [],
      "source": [
        "from wideresnet import load_pretrained_model, get_grads_wrt_input\n",
        "path_to_pretrained_model = \"./CIFAR10_MODEL.pt\"\n",
        "model = load_pretrained_model(path_to_pretrained_model)\n",
        "\n",
        "batch_size = 4\n",
        "x = onp.random.randn(batch_size, 3, 32, 32)\n",
        "y = onp.random.randint(10, size=(batch_size, ))\n",
        "\n",
        "log_p, input_grads = get_grads_wrt_input(model, x)\n",
        "log_p, input_grads = get_grads_wrt_input(model, x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC_6EBw-Flmz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}